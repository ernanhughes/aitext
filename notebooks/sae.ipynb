{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define Sparse Autoencoder\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.01),  # Helps sparsity\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Output values between 0-1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ollama\n",
    "\n",
    "# Function to get embeddings using Ollama (with error handling)\n",
    "def get_embedding(text):\n",
    "    try:\n",
    "        embedding_data = ollama.embeddings(model=\"mxbai-embed-large\", prompt=text)\n",
    "        embedding_vector = torch.tensor(embedding_data[\"embedding\"], dtype=torch.float32)  # Convert to tensor\n",
    "        return embedding_vector\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error generating embedding: {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1024  # Match Ollama embedding size\n",
    "hidden_dim = 64  # Compressed representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sparse features: [[0.17408113 0.10068728 0.0266986  0.         0.         0.\n",
      "  0.         0.08642361 0.         0.        ]\n",
      " [0.1961816  0.13727127 0.         0.         0.         0.03275107\n",
      "  0.00662035 0.05166993 0.         0.        ]\n",
      " [0.1979455  0.09991568 0.         0.         0.         0.00894872\n",
      "  0.         0.05397782 0.         0.        ]\n",
      " [0.17810443 0.19679238 0.         0.         0.         0.\n",
      "  0.         0.30340973 0.         0.        ]\n",
      " [0.06918554 0.15267411 0.03933194 0.         0.         0.\n",
      "  0.         0.08321735 0.         0.02684967]\n",
      " [0.04107302 0.15781884 0.05910005 0.         0.         0.\n",
      "  0.         0.06845911 0.         0.00673035]\n",
      " [0.22568682 0.18624441 0.         0.         0.         0.\n",
      "  0.         0.249841   0.         0.00278136]\n",
      " [0.27213317 0.12637684 0.         0.         0.         0.00529841\n",
      "  0.         0.18601379 0.         0.        ]\n",
      " [0.24132699 0.16936474 0.         0.         0.         0.04576051\n",
      "  0.         0.17641509 0.         0.        ]\n",
      " [0.09542193 0.16140202 0.06676719 0.         0.         0.\n",
      "  0.         0.1597268  0.         0.        ]]\n",
      "Feature shape: (10, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(embeddings, sae_model):\n",
    "    \"\"\"Extracts sparse features from LLM embeddings.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        features = sae_model.encoder(torch.tensor(embeddings, dtype=torch.float32))\n",
    "    return features.numpy()\n",
    "\n",
    "# Simulated token embeddings (100-dimensional)\n",
    "token_embeddings = np.random.rand(10, 100)  # 10 tokens, 100 features each\n",
    "features = extract_features(token_embeddings, model)\n",
    "print(\"Extracted sparse features:\", features)\n",
    "print(\"Feature shape:\", features.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
