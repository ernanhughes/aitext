{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from ai.txt saved to database.\n",
      "('AI', 0.5262972116470337) : \"In the ever-evolving landscape of artificial intelligence, language models continue to demonstrate unprecedented capabilities in generating human-like text.\"\n",
      "('AI', 0.6308665871620178) : \"The significance of sustainable energy solutions cannot be overstated in the modern era of climate change and environmental awareness.\"\n",
      "('AI', 0.8574424386024475) : \"The Renaissance was a pivotal period in human history, characterized by remarkable advancements in art, science, and philosophy.\"\n",
      "('AI', 0.7112773656845093) : \"Machine learning algorithms leverage vast datasets to optimize predictive performance in a variety of real-world applications.\"\n",
      "('Human', 0.6411317586898804) : \"Throughout history, civilizations have relied on innovation to drive progress and enhance societal development.\"\n",
      "('AI', 0.8603178858757019) : \"The impact of artificial intelligence on the global workforce is a topic of considerable debate among experts in the field.\"\n",
      "('Human', 0.9688016176223755) : \"While natural language processing has significantly improved over the past decade, challenges in context retention and sentiment analysis remain.\"\n",
      "('Human', 0.6212611198425293) : \"Technological advancements have revolutionized the way humans interact with digital ecosystems, fostering unprecedented levels of connectivity.\"\n",
      "('Human', 0.8444640040397644) : \"The intricate relationship between data privacy and cybersecurity continues to shape global policies in the digital age.\"\n",
      "('Human', 0.7971766591072083) : \"Future developments in artificial intelligence are expected to further blur the distinction between human and machine-generated content.\"\n",
      "Results from human.txt saved to database.\n",
      "('Human', 0.9575759768486023) : Honestly, I had no idea AI could write this well until I saw ChatGPT in action.\n",
      "('Human', 0.585211992263794) : I still remember that summer when we stayed up all night talking—somehow, those moments stick with you forever.\n",
      "('AI', 0.7112950086593628) : I tried making sourdough bread last weekend, and let’s just say it was more of a rock than a loaf.\n",
      "('Human', 0.9911134839057922) : Look, I know AI is cool and all, but I still don’t trust a machine to write my wedding vows.\n",
      "('Human', 0.6593263149261475) : You ever get that weird feeling that you left the stove on, even though you know you didn’t?\n",
      "('Human', 0.7946497201919556) : The coffee at that new place on 5th Street is honestly overrated—too bitter and way overpriced.\n",
      "('AI', 0.9335265755653381) : I can’t explain why, but I really love the sound of rain hitting the roof at night.\n",
      "('Human', 0.944594144821167) : We spent the whole day hiking, only to realize we took the wrong trail back—thankfully, we had snacks!\n",
      "('AI', 0.5021772384643555) : I swear, my cat understands English but just chooses to ignore me unless I say ‘treats.’\n",
      "('Human', 0.6643994450569153) : Grandma always had the best stories about growing up in the countryside, and I wish I’d written them down.\n",
      "Markdown report saved as classification_report.md\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from typing import List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "# Set device for model\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base-openai-detector\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base-openai-detector\")\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0 if DEVICE == \"cuda:0\" else -1)\n",
    "\n",
    "# Initialize SQLite database\n",
    "DB_NAME = \"classification_results.db\"\n",
    "\n",
    "def initialize_database():\n",
    "    \"\"\"Initializes the SQLite database and creates the classifications table if it doesn't exist.\"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS classifications (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            filename TEXT,\n",
    "            line_text TEXT,\n",
    "            label TEXT,\n",
    "            confidence REAL\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def classify_text(sentences: List[str]) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Classifies a list of sentences as 'Human' or 'AI' with confidence scores.\n",
    "\n",
    "    :param sentences: List of text inputs to classify.\n",
    "    :return: List of tuples containing the predicted label ('Human' or 'AI') and confidence score.\n",
    "    \"\"\"\n",
    "    results = pipe(sentences)\n",
    "    return [(\"Human\" if res[\"label\"] == \"Real\" else \"AI\", res[\"score\"]) for res in results]\n",
    "\n",
    "def classify_file(filename: str) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Reads a file line by line, classifies each line as 'Human' or 'AI', prints the results,\n",
    "    and stores them in an SQLite database.\n",
    "\n",
    "    :param filename: Name of the text file to classify.\n",
    "    :return: List of tuples containing classification results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [line.strip() for line in file if line.strip()]  # Remove empty lines\n",
    "\n",
    "    if not lines:\n",
    "        print(f\"Warning: {filename} is empty or contains only whitespace.\")\n",
    "        return results\n",
    "    \n",
    "    classifications = classify_text(lines)\n",
    "\n",
    "    # Store results in SQLite\n",
    "    save_to_database(filename, lines, classifications)\n",
    "    \n",
    "    # Print results\n",
    "    for line, classification in zip(lines, classifications):\n",
    "        print(f\"{classification} : {line}\")\n",
    "        results.append(classification)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_to_database(filename: str, lines: List[str], classifications: List[Tuple[str, float]]):\n",
    "    \"\"\"\n",
    "    Saves classification results to an SQLite database.\n",
    "\n",
    "    :param filename: Name of the source file.\n",
    "    :param lines: List of text lines from the file.\n",
    "    :param classifications: List of classification results (label, confidence).\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    data = [(filename, line, label, confidence) for line, (label, confidence) in zip(lines, classifications)]\n",
    "    cursor.executemany(\"INSERT INTO classifications (filename, line_text, label, confidence) VALUES (?, ?, ?, ?)\", data)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Results from {filename} saved to database.\")\n",
    "\n",
    "def generate_markdown_report(output_filename: str = \"classification_report.md\"):\n",
    "    \"\"\"\n",
    "    Generates a Markdown report summarizing classification results.\n",
    "\n",
    "    :param output_filename: Name of the output Markdown file.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch classification summary\n",
    "    cursor.execute(\"SELECT label, COUNT(*) FROM classifications GROUP BY label\")\n",
    "    summary_data = cursor.fetchall()\n",
    "\n",
    "    total_count = sum(count for _, count in summary_data)\n",
    "    human_count = sum(count for label, count in summary_data if label == \"Human\")\n",
    "    ai_count = total_count - human_count\n",
    "\n",
    "    human_percent = (human_count / total_count * 100) if total_count else 0\n",
    "    ai_percent = (ai_count / total_count * 100) if total_count else 0\n",
    "\n",
    "    # Fetch detailed data\n",
    "    cursor.execute(\"SELECT filename, line_text, label, confidence FROM classifications ORDER BY filename\")\n",
    "    detailed_results = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Generate Markdown content\n",
    "    markdown_content = f\"\"\"# Classification Report\n",
    "\n",
    "## Summary\n",
    "| Label  | Count | Percentage |\n",
    "|--------|-------|------------|\n",
    "| Human  | {human_count}   | {human_percent:.2f}% |\n",
    "| AI     | {ai_count}   | {ai_percent:.2f}% |\n",
    "| **Total** | {total_count} | 100.00% |\n",
    "\n",
    "## Detailed Results\n",
    "| Filename | Text | Label | Confidence |\n",
    "|----------|------|-------|------------|\n",
    "\"\"\"\n",
    "\n",
    "    for filename, line_text, label, confidence in detailed_results:\n",
    "        sanitized_text = line_text.replace(\"|\", \"\\\\|\")  # Escape Markdown pipes\n",
    "        markdown_content += f\"| {filename} | {sanitized_text} | {label} | {confidence:.2f} |\\n\"\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "    print(f\"Markdown report saved as {output_filename}\")\n",
    "\n",
    "# Initialize database\n",
    "initialize_database()\n",
    "\n",
    "# Run classification and store results\n",
    "classify_file(\"ai.txt\")\n",
    "classify_file(\"human.txt\")\n",
    "\n",
    "# Generate markdown report\n",
    "generate_markdown_report()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
